<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HVATP Receiver - Scan & Decode</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 900px;
            width: 100%;
            margin: 0 auto;
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .content {
            padding: 40px;
        }

        .camera-container {
            position: relative;
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 30px;
        }

        #videoElement {
            width: 100%;
            height: auto;
            display: block;
        }

        .camera-overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80%;
            height: 80%;
            border: 3px dashed rgba(255, 255, 255, 0.6);
            border-radius: 10px;
            pointer-events: none;
        }

        .scan-indicator {
            position: absolute;
            top: 10px;
            right: 10px;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-weight: 600;
        }

        .scan-indicator.active {
            background: rgba(76, 175, 80, 0.9);
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .btn {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            border: none;
            padding: 15px 40px;
            font-size: 1.1em;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s;
            display: inline-block;
            font-weight: 600;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(240, 147, 251, 0.4);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-bottom: 30px;
        }

        .stats {
            background: #f8f9ff;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
        }

        .stat-item {
            text-align: center;
        }

        .stat-value {
            font-size: 2em;
            font-weight: 700;
            color: #f5576c;
        }

        .stat-label {
            color: #666;
            margin-top: 5px;
        }

        .progress-bar {
            width: 100%;
            height: 10px;
            background: #e0e0e0;
            border-radius: 5px;
            overflow: hidden;
            margin: 20px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            width: 0%;
            transition: width 0.3s;
        }

        .received-data {
            background: #f8f9ff;
            padding: 20px;
            border-radius: 10px;
            display: none;
        }

        .received-data.active {
            display: block;
        }

        .received-data h3 {
            margin-bottom: 15px;
            color: #333;
        }

        .received-data pre {
            background: #fff;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            max-height: 200px;
            overflow-y: auto;
            font-size: 0.9em;
        }

        .logs {
            background: #f8f9ff;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
            max-height: 200px;
            overflow-y: auto;
        }

        .log-entry {
            padding: 8px;
            margin: 5px 0;
            background: white;
            border-radius: 5px;
            font-size: 0.9em;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .log-time {
            color: #999;
            font-size: 0.8em;
        }

        .log-success {
            border-left: 4px solid #4caf50;
        }

        .log-error {
            border-left: 4px solid #f44336;
        }

        .log-info {
            border-left: 4px solid #2196f3;
        }

        @media (max-width: 600px) {
            .container {
                border-radius: 0;
            }

            .content {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üì± HVATP Receiver</h1>
            <p>Point your camera at the sender's screen</p>
        </div>

        <div class="content">
            <div class="camera-container">
                <video id="videoElement" autoplay playsinline></video>
                <canvas id="canvasElement" style="display: none;"></canvas>
                <div class="camera-overlay"></div>
                <div class="scan-indicator" id="scanIndicator">Ready to Scan</div>
            </div>

            <div class="controls">
                <button class="btn" id="startBtn">üì∑ Start Camera</button>
                <button class="btn" id="stopBtn" disabled>‚èπ Stop</button>
                <button class="btn" id="saveBtn" disabled>üíæ Save File</button>
            </div>

            <div style="text-align: center; margin: 15px 0; padding: 10px; background: #f8f9ff; border-radius: 5px;">
                <label>
                    <input type="checkbox" id="enableAudio" style="margin-right: 8px;">
                    <strong>Enable Audio Detection</strong> (experimental - detects sync beeps)
                </label>
            </div>

            <div class="stats">
                <div class="stats-grid">
                    <div class="stat-item">
                        <div class="stat-value" id="framesDetected">0</div>
                        <div class="stat-label">Frames Detected</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="successRate">0%</div>
                        <div class="stat-label">Success Rate</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="dataReceived">0 KB</div>
                        <div class="stat-label">Data Received</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="progress">0%</div>
                        <div class="stat-label">Progress</div>
                    </div>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressBar"></div>
                </div>
            </div>

            <div class="received-data" id="receivedData">
                <h3>üì¶ Received Data Preview</h3>
                <pre id="dataPreview"></pre>
            </div>

            <div class="logs" id="logs">
                <h3 style="margin-bottom: 10px;">üìã Activity Log</h3>
                <div id="logEntries"></div>
            </div>
        </div>
    </div>

    <script>
        // Simple Visual Decoder - matches the encoder from sender.html
        class SimpleVisualDecoder {
            constructor() {
                this.moduleCount = 100; // Match sender
                this.colorPalettes = {
                    'HIGH_DENSITY': ['#000000', '#FFFFFF', '#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF', '#00FFFF'],
                    'BALANCED': ['#000000', '#FFFFFF', '#FF0000', '#0000FF'],
                    'ROBUST': ['#000000', '#FFFFFF']
                };
                this.lastFrameId = -1;
            }

            // Detect if image contains our custom visual frame
            detectFrame(imageData) {
                const { data, width, height } = imageData;
                
                // Look for finder patterns (black squares in corners)
                const moduleSize = Math.floor(Math.min(width, height) / this.moduleCount);
                if (moduleSize < 2) return null;
                
                // Check for finder pattern in top-left corner
                const patternSize = 10 * moduleSize;
                if (!this.hasFinderPattern(data, width, 0, 0, patternSize, moduleSize)) {
                    return null;
                }
                
                return { moduleSize };
            }

            hasFinderPattern(data, width, x, y, patternSize, moduleSize) {
                // Check if there's a black square pattern
                let blackPixels = 0;
                let totalSamples = 0;
                
                for (let dy = 0; dy < patternSize; dy += moduleSize) {
                    for (let dx = 0; dx < patternSize; dx += moduleSize) {
                        const px = x + dx;
                        const py = y + dy;
                        if (px >= width || py >= width) continue;
                        
                        const idx = (py * width + px) * 4;
                        const r = data[idx];
                        const g = data[idx + 1];
                        const b = data[idx + 2];
                        const brightness = (r + g + b) / 3;
                        
                        if (brightness < 128) blackPixels++;
                        totalSamples++;
                    }
                }
                
                // Should have significant black area (finder pattern)
                return totalSamples > 0 && (blackPixels / totalSamples) > 0.4;
            }

            // Extract frame information
            extractFrameInfo(imageData, moduleSize) {
                const { data, width, height } = imageData;
                
                // Try to extract frame text from bottom of image
                let frameId = -1;
                let totalFrames = -1;
                let dataLength = -1;
                
                // Sample bottom area for white text
                const textY = height - 20;
                const textStartX = 10;
                const textEndX = 200;
                
                // Simple OCR-like detection (look for white pixels in text area)
                // This is simplified - just generate hash for uniqueness
                let hash = 0;
                const sampleCount = 100;
                
                for (let i = 0; i < sampleCount; i++) {
                    const x = Math.floor(Math.random() * width);
                    const y = Math.floor(Math.random() * height);
                    const idx = (y * width + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    hash = ((hash << 5) - hash) + r + g + b;
                    hash = hash & hash;
                }
                
                return {
                    detected: true,
                    hash: Math.abs(hash),
                    timestamp: Date.now(),
                    frameId: frameId,
                    totalFrames: totalFrames,
                    dataLength: dataLength
                };
            }

            // Decode the visual frame
            decodeFrame(imageData) {
                const detection = this.detectFrame(imageData);
                if (!detection) return null;
                
                const frameInfo = this.extractFrameInfo(imageData, detection.moduleSize);
                
                // Extract data from modules
                const decodedData = this.extractModuleData(imageData, detection.moduleSize);
                
                return {
                    ...frameInfo,
                    data: decodedData,
                    moduleSize: detection.moduleSize
                };
            }

            extractModuleData(imageData, moduleSize) {
                const { data, width, height } = imageData;
                
                // Get color palette based on mode detection
                const palette = this.detectPaletteMode(data, width, height, moduleSize);
                const colorPalette = this.colorPalettes[palette];
                const bitsPerModule = Math.log2(colorPalette.length);
                
                let bitString = '';
                
                // Sample modules and extract color indices
                const modules = Math.floor(Math.min(width, height) / moduleSize);
                
                for (let y = 0; y < modules && y < this.moduleCount; y++) {
                    for (let x = 0; x < modules && x < this.moduleCount; x++) {
                        const px = x * moduleSize + Math.floor(moduleSize / 2);
                        const py = y * moduleSize + Math.floor(moduleSize / 2);
                        
                        if (px >= width || py >= height) continue;
                        
                        const idx = (py * width + px) * 4;
                        const r = data[idx];
                        const g = data[idx + 1];
                        const b = data[idx + 2];
                        
                        // Match to nearest color in palette
                        const colorIndex = this.findNearestColor(r, g, b, colorPalette);
                        
                        // Convert color index to bits
                        const bits = colorIndex.toString(2).padStart(Math.floor(bitsPerModule), '0');
                        bitString += bits;
                    }
                }
                
                // Convert bits back to characters
                let extractedData = '';
                for (let i = 0; i < bitString.length; i += 8) {
                    const byte = bitString.substr(i, 8);
                    if (byte.length === 8) {
                        const charCode = parseInt(byte, 2);
                        if (charCode > 0 && charCode < 128) { // Valid ASCII
                            extractedData += String.fromCharCode(charCode);
                        }
                    }
                }
                
                // Trim to reasonable length
                if (extractedData.length > 300) {
                    extractedData = extractedData.substring(0, 300);
                }
                
                return extractedData;
            }

            detectPaletteMode(data, width, height, moduleSize) {
                // Sample some modules and count unique colors
                const colors = new Set();
                const samples = 20;
                
                for (let i = 0; i < samples; i++) {
                    const x = Math.floor(Math.random() * (width / moduleSize)) * moduleSize;
                    const y = Math.floor(Math.random() * (height / moduleSize)) * moduleSize;
                    const idx = (y * width + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    colors.add(`${r},${g},${b}`);
                }
                
                // Determine mode based on color count
                if (colors.size >= 7) return 'HIGH_DENSITY';
                if (colors.size >= 3) return 'BALANCED';
                return 'ROBUST';
            }

            findNearestColor(r, g, b, palette) {
                let minDist = Infinity;
                let nearestIndex = 0;
                
                palette.forEach((color, index) => {
                    const cr = parseInt(color.substr(1, 2), 16);
                    const cg = parseInt(color.substr(3, 2), 16);
                    const cb = parseInt(color.substr(5, 2), 16);
                    
                    const dist = Math.sqrt(
                        Math.pow(r - cr, 2) +
                        Math.pow(g - cg, 2) +
                        Math.pow(b - cb, 2)
                    );
                    
                    if (dist < minDist) {
                        minDist = dist;
                        nearestIndex = index;
                    }
                });
                
                return nearestIndex;
            }
        }

        // App state
        let stream = null;
        let isScanning = false;
        let isReceiving = false; // NEW: Only true after detecting start signal
        let scanInterval = null;
        let receivedFrames = new Map();
        let frameHashes = new Set(); // Track unique frames by hash
        let totalFrames = 0;
        let totalData = '';
        let decoder = new SimpleVisualDecoder();
        let lastDetectionTime = 0;
        let detectionCooldown = 200; // ms between frame captures
        let startSignalDetected = false;

        // Elements
        const videoElement = document.getElementById('videoElement');
        const canvasElement = document.getElementById('canvasElement');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const saveBtn = document.getElementById('saveBtn');
        const scanIndicator = document.getElementById('scanIndicator');
        const ctx = canvasElement.getContext('2d');

        // Logging
        function addLog(message, type = 'info') {
            const logEntries = document.getElementById('logEntries');
            const entry = document.createElement('div');
            entry.className = `log-entry log-${type}`;
            
            const time = new Date().toLocaleTimeString();
            entry.innerHTML = `<span class="log-time">${time}</span><span>${message}</span>`;
            
            logEntries.insertBefore(entry, logEntries.firstChild);
            
            // Keep only last 20 logs
            while (logEntries.children.length > 20) {
                logEntries.removeChild(logEntries.lastChild);
            }
        }

        // Start camera
        startBtn.addEventListener('click', async () => {
            try {
                const enableAudio = document.getElementById('enableAudio').checked;
                
                const constraints = { 
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                };
                
                // Add audio if enabled
                if (enableAudio) {
                    constraints.audio = {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    };
                    addLog('Requesting camera + microphone access...', 'info');
                } else {
                    addLog('Requesting camera access...', 'info');
                }
                
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                
                videoElement.srcObject = stream;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                isScanning = true;
                
                if (enableAudio) {
                    addLog('Camera + microphone started successfully', 'success');
                    setupAudioDetection(stream);
                } else {
                    addLog('Camera started successfully', 'success');
                }
                
                scanIndicator.textContent = 'Scanning...';
                scanIndicator.classList.add('active');
                
                // Start scanning
                scanInterval = setInterval(scanFrame, 100); // Scan every 100ms
                
            } catch (err) {
                addLog('Failed to access camera/microphone: ' + err.message, 'error');
                alert('Could not access camera/microphone. Please grant permissions and try again.');
            }
        });

        // Stop camera
        stopBtn.addEventListener('click', () => {
            stopScanning();
        });

        function stopScanning() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            if (scanInterval) {
                clearInterval(scanInterval);
                scanInterval = null;
            }
            
            isScanning = false;
            isReceiving = false;
            startSignalDetected = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            scanIndicator.textContent = 'Stopped';
            scanIndicator.classList.remove('active');
            scanIndicator.style.background = '';
            
            addLog('Scanning stopped', 'info');
        }

        // Audio detection setup
        function setupAudioDetection(mediaStream) {
            try {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(mediaStream);
                const analyser = audioContext.createAnalyser();
                
                analyser.fftSize = 2048;
                source.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                // Listen for audio beeps
                let lastBeepTime = 0;
                let beepSequence = [];
                
                function detectBeeps() {
                    if (!isScanning) return;
                    
                    analyser.getByteFrequencyData(dataArray);
                    
                    // Check for frequencies around 1000 Hz (base frequency)
                    // Bin index = frequency * fftSize / sampleRate
                    // For 1000 Hz at 44100 sample rate with 2048 FFT: ~46
                    const targetBin = Math.floor(1000 * analyser.fftSize / audioContext.sampleRate);
                    const binRange = 10; // Check ¬±10 bins
                    
                    let maxAmplitude = 0;
                    let peakFrequency = 0;
                    for (let i = Math.max(0, targetBin - binRange); i < Math.min(bufferLength, targetBin + binRange); i++) {
                        if (dataArray[i] > maxAmplitude) {
                            maxAmplitude = dataArray[i];
                            peakFrequency = (i * audioContext.sampleRate) / analyser.fftSize;
                        }
                    }
                    
                    // Detect beep (threshold: 150/255)
                    if (maxAmplitude > 150) {
                        const now = Date.now();
                        if (now - lastBeepTime > 50) { // Debounce 50ms
                            beepSequence.push({ freq: peakFrequency, time: now });
                            
                            // Keep only recent beeps (last 2 seconds)
                            beepSequence = beepSequence.filter(b => now - b.time < 2000);
                            
                            // Detect triple beep pattern (metadata announcement)
                            if (beepSequence.length >= 3 && !startSignalDetected) {
                                const lastThree = beepSequence.slice(-3);
                                const timeDiff1 = lastThree[1].time - lastThree[0].time;
                                const timeDiff2 = lastThree[2].time - lastThree[1].time;
                                
                                // Check if beeps are evenly spaced (~150ms apart)
                                if (timeDiff1 > 100 && timeDiff1 < 200 && timeDiff2 > 100 && timeDiff2 < 200) {
                                    startSignalDetected = true;
                                    isReceiving = true;
                                    addLog('üéµ START SIGNAL DETECTED - Transfer beginning!', 'success');
                                    scanIndicator.textContent = 'Transfer Started - Capturing...';
                                    scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
                                }
                            }
                            
                            // Log regular sync beeps
                            if (startSignalDetected) {
                                addLog(`üîä Sync beep (${Math.round(peakFrequency)} Hz)`, 'info');
                            }
                            
                            lastBeepTime = now;
                        }
                    }
                    
                    requestAnimationFrame(detectBeeps);
                }
                
                detectBeeps();
                addLog('Audio detection active - listening for sync beeps', 'success');
                
            } catch (err) {
                addLog('Audio detection setup failed: ' + err.message, 'error');
            }
        }

        // Scan frame for QR code
        function scanFrame() {
            if (!isScanning) return;

            // Cooldown between detections
            const now = Date.now();
            if (now - lastDetectionTime < detectionCooldown) return;

            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            
            if (canvasElement.width === 0) return;

            ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            const imageData = ctx.getImageData(0, 0, canvasElement.width, canvasElement.height);
            
            // Use our custom decoder
            const decoded = decoder.decodeFrame(imageData);
            
            if (decoded && decoded.detected) {
                // If audio not enabled, start receiving on first frame detection
                if (!document.getElementById('enableAudio').checked && !isReceiving) {
                    isReceiving = true;
                    startSignalDetected = true;
                    addLog('üëÅÔ∏è VISUAL FRAME DETECTED - Transfer starting!', 'success');
                    scanIndicator.textContent = 'Transfer Started - Capturing...';
                    scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
                }
                
                // Only capture frames after start signal (or first visual detection)
                if (!isReceiving) {
                    scanIndicator.textContent = 'Waiting for start signal...';
                    return;
                }
                
                lastDetectionTime = now;
                
                // Check if this is a new frame (by hash)
                if (!frameHashes.has(decoded.hash)) {
                    frameHashes.add(decoded.hash);
                    
                    const frameId = receivedFrames.size;
                    receivedFrames.set(frameId, decoded.data);
                    totalData += decoded.data;
                    
                    addLog(`‚úì Frame ${frameId + 1} captured (${decoded.data.length} bytes)`, 'success');
                    scanIndicator.textContent = `Captured ${frameId + 1} frames`;
                    
                    updateStats();
                }
            }
        }

        // Update statistics
        function updateStats() {
            const detected = receivedFrames.size;
            const total = totalFrames || detected; // Use detected count if total unknown
            const progress = total > 0 ? (detected / total) * 100 : 0;
            const successRate = total > 0 ? ((detected / total) * 100).toFixed(1) : 0;

            document.getElementById('framesDetected').textContent = detected;
            document.getElementById('successRate').textContent = successRate + '%';
            document.getElementById('progress').textContent = progress.toFixed(1) + '%';
            document.getElementById('progressBar').style.width = Math.min(progress, 100) + '%';
            document.getElementById('dataReceived').textContent = (totalData.length / 1024).toFixed(1) + ' KB';
            
            // Enable save button if we have any data
            if (totalData.length > 0) {
                saveBtn.disabled = false;
                document.getElementById('receivedData').classList.add('active');
                document.getElementById('dataPreview').textContent = totalData.substring(0, 500) + 
                    (totalData.length > 500 ? '\n... (truncated)' : '');
            }
        }

        // Transfer complete
        function handleTransferComplete() {
            stopScanning();
            
            document.getElementById('receivedData').classList.add('active');
            document.getElementById('dataPreview').textContent = totalData.substring(0, 500) + 
                (totalData.length > 500 ? '\n... (truncated)' : '');
            
            saveBtn.disabled = false;
            addLog('Transfer complete! üéâ', 'success');
            scanIndicator.textContent = 'Complete!';
        }

        // Save file
        saveBtn.addEventListener('click', () => {
            const blob = new Blob([totalData], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'received_file.txt';
            a.click();
            URL.revokeObjectURL(url);
            
            addLog('File saved successfully', 'success');
        });

        // Initialize
        addLog('Receiver ready. Click "Start Camera" to begin.', 'info');
    </script>
</body>
</html>
