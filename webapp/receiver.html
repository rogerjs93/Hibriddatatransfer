<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HVATP Receiver - Scan & Decode</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 900px;
            width: 100%;
            margin: 0 auto;
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .content {
            padding: 40px;
        }

        .camera-container {
            position: relative;
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 30px;
        }

        #videoElement {
            width: 100%;
            height: auto;
            display: block;
        }

        .camera-overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80%;
            height: 80%;
            border: 3px dashed rgba(255, 255, 255, 0.6);
            border-radius: 10px;
            pointer-events: none;
        }

        .scan-indicator {
            position: absolute;
            top: 10px;
            right: 10px;
            background: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-weight: 600;
        }

        .scan-indicator.active {
            background: rgba(76, 175, 80, 0.9);
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .btn {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            border: none;
            padding: 15px 40px;
            font-size: 1.1em;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s;
            display: inline-block;
            font-weight: 600;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(240, 147, 251, 0.4);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-bottom: 30px;
        }

        .stats {
            background: #f8f9ff;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
        }

        .stat-item {
            text-align: center;
        }

        .stat-value {
            font-size: 2em;
            font-weight: 700;
            color: #f5576c;
        }

        .stat-label {
            color: #666;
            margin-top: 5px;
        }

        .progress-bar {
            width: 100%;
            height: 10px;
            background: #e0e0e0;
            border-radius: 5px;
            overflow: hidden;
            margin: 20px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            width: 0%;
            transition: width 0.3s;
        }

        .received-data {
            background: #f8f9ff;
            padding: 20px;
            border-radius: 10px;
            display: none;
        }

        .received-data.active {
            display: block;
        }

        .received-data h3 {
            margin-bottom: 15px;
            color: #333;
        }

        .received-data pre {
            background: #fff;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            max-height: 200px;
            overflow-y: auto;
            font-size: 0.9em;
        }

        .logs {
            background: #f8f9ff;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
            max-height: 200px;
            overflow-y: auto;
        }

        .log-entry {
            padding: 8px;
            margin: 5px 0;
            background: white;
            border-radius: 5px;
            font-size: 0.9em;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .log-time {
            color: #999;
            font-size: 0.8em;
        }

        .log-success {
            border-left: 4px solid #4caf50;
        }

        .log-error {
            border-left: 4px solid #f44336;
        }

        .log-info {
            border-left: 4px solid #2196f3;
        }

        @media (max-width: 600px) {
            .container {
                border-radius: 0;
            }

            .content {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üì± HVATP Receiver</h1>
            <p>Point your camera at the sender's screen</p>
        </div>

        <div class="content">
            <div class="camera-container">
                <video id="videoElement" autoplay playsinline></video>
                <canvas id="canvasElement" style="display: none;"></canvas>
                <div class="camera-overlay"></div>
                <div class="scan-indicator" id="scanIndicator">Ready to Scan</div>
            </div>

            <div class="controls">
                <button class="btn" id="startBtn">üì∑ Start Camera</button>
                <button class="btn" id="startReceivingBtn" disabled>‚ñ∂ Start Receiving</button>
                <button class="btn" id="stopBtn" disabled>‚èπ Stop</button>
                <button class="btn" id="saveBtn" disabled>üíæ Save File</button>
            </div>

            <div style="text-align: center; margin: 15px 0; padding: 10px; background: #f8f9ff; border-radius: 5px;">
                <label>
                    <input type="checkbox" id="enableAudio" style="margin-right: 8px;">
                    <strong>Enable Audio Detection</strong> (experimental - detects sync beeps)
                </label>
            </div>

            <div class="stats">
                <div class="stats-grid">
                    <div class="stat-item">
                        <div class="stat-value" id="framesDetected">0</div>
                        <div class="stat-label">Frames Detected</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="successRate">0%</div>
                        <div class="stat-label">Success Rate</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="dataReceived">0 KB</div>
                        <div class="stat-label">Data Received</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="progress">0%</div>
                        <div class="stat-label">Progress</div>
                    </div>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressBar"></div>
                </div>
            </div>

            <div class="received-data" id="receivedData">
                <h3>üì¶ Received Data Preview</h3>
                <pre id="dataPreview"></pre>
            </div>

            <div class="logs" id="logs">
                <h3 style="margin-bottom: 10px;">üìã Activity Log</h3>
                <div id="logEntries"></div>
            </div>
        </div>
    </div>

    <script>
        // Simple Visual Decoder - matches the encoder from sender.html
        class SimpleVisualDecoder {
            constructor() {
                this.moduleCount = 100; // Match sender
                this.colorPalettes = {
                    'HIGH_DENSITY': ['#000000', '#FFFFFF', '#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF', '#00FFFF'],
                    'BALANCED': ['#000000', '#FFFFFF', '#FF0000', '#0000FF'],
                    'ROBUST': ['#000000', '#FFFFFF']
                };
                this.lastFrameId = -1;
            }

            // Detect if image contains our custom visual frame
            detectFrame(imageData) {
                const { data, width, height } = imageData;
                
                // Look for finder patterns (black squares in corners)
                const moduleSize = Math.floor(Math.min(width, height) / this.moduleCount);
                if (moduleSize < 2) return null;
                
                // Check for finder pattern in top-left corner
                const patternSize = 10 * moduleSize;
                if (!this.hasFinderPattern(data, width, 0, 0, patternSize, moduleSize)) {
                    return null;
                }
                
                return { moduleSize };
            }

            hasFinderPattern(data, width, x, y, patternSize, moduleSize) {
                // Check if there's a black square pattern
                let blackPixels = 0;
                let totalSamples = 0;
                
                for (let dy = 0; dy < patternSize; dy += moduleSize) {
                    for (let dx = 0; dx < patternSize; dx += moduleSize) {
                        const px = x + dx;
                        const py = y + dy;
                        if (px >= width || py >= width) continue;
                        
                        const idx = (py * width + px) * 4;
                        const r = data[idx];
                        const g = data[idx + 1];
                        const b = data[idx + 2];
                        const brightness = (r + g + b) / 3;
                        
                        if (brightness < 128) blackPixels++;
                        totalSamples++;
                    }
                }
                
                // Should have significant black area (finder pattern)
                return totalSamples > 0 && (blackPixels / totalSamples) > 0.4;
            }

            // Extract frame information
            extractFrameInfo(imageData, moduleSize) {
                const { data, width, height } = imageData;
                
                // Try to extract frame text from bottom of image
                let frameId = -1;
                let totalFrames = -1;
                let dataLength = -1;
                
                // Sample bottom area for white text
                const textY = height - 20;
                const textStartX = 10;
                const textEndX = 200;
                
                // Simple OCR-like detection (look for white pixels in text area)
                // This is simplified - just generate hash for uniqueness
                let hash = 0;
                const sampleCount = 100;
                
                for (let i = 0; i < sampleCount; i++) {
                    const x = Math.floor(Math.random() * width);
                    const y = Math.floor(Math.random() * height);
                    const idx = (y * width + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    hash = ((hash << 5) - hash) + r + g + b;
                    hash = hash & hash;
                }
                
                return {
                    detected: true,
                    hash: Math.abs(hash),
                    timestamp: Date.now(),
                    frameId: frameId,
                    totalFrames: totalFrames,
                    dataLength: dataLength
                };
            }

            // Decode the visual frame
            decodeFrame(imageData) {
                const detection = this.detectFrame(imageData);
                if (!detection) return null;
                
                const frameInfo = this.extractFrameInfo(imageData, detection.moduleSize);
                
                // Extract data from modules
                const decodedData = this.extractModuleData(imageData, detection.moduleSize);
                
                return {
                    ...frameInfo,
                    data: decodedData,
                    moduleSize: detection.moduleSize
                };
            }

            extractModuleData(imageData, moduleSize) {
                const { data, width, height } = imageData;
                
                // Get color palette based on mode detection
                const palette = this.detectPaletteMode(data, width, height, moduleSize);
                const colorPalette = this.colorPalettes[palette];
                const bitsPerModule = Math.log2(colorPalette.length);
                
                let bitString = '';
                
                // Sample modules and extract color indices
                const modules = Math.floor(Math.min(width, height) / moduleSize);
                
                for (let y = 0; y < modules && y < this.moduleCount; y++) {
                    for (let x = 0; x < modules && x < this.moduleCount; x++) {
                        const px = x * moduleSize + Math.floor(moduleSize / 2);
                        const py = y * moduleSize + Math.floor(moduleSize / 2);
                        
                        if (px >= width || py >= height) continue;
                        
                        const idx = (py * width + px) * 4;
                        const r = data[idx];
                        const g = data[idx + 1];
                        const b = data[idx + 2];
                        
                        // Match to nearest color in palette
                        const colorIndex = this.findNearestColor(r, g, b, colorPalette);
                        
                        // Convert color index to bits
                        const bits = colorIndex.toString(2).padStart(Math.floor(bitsPerModule), '0');
                        bitString += bits;
                    }
                }
                
                // Convert bits back to bytes (NO ASCII FILTERING - keep all bytes 0-255)
                let extractedBytes = [];
                for (let i = 0; i < bitString.length; i += 8) {
                    const byte = bitString.substr(i, 8);
                    if (byte.length === 8) {
                        const byteValue = parseInt(byte, 2);
                        extractedBytes.push(byteValue); // Store all bytes, not just ASCII
                    }
                }
                
                // Trim to reasonable length (300 bytes per frame)
                if (extractedBytes.length > 300) {
                    extractedBytes = extractedBytes.slice(0, 300);
                }
                
                return extractedBytes; // Return byte array instead of string
            }

            detectPaletteMode(data, width, height, moduleSize) {
                // Sample some modules and count unique colors
                const colors = new Set();
                const samples = 20;
                
                for (let i = 0; i < samples; i++) {
                    const x = Math.floor(Math.random() * (width / moduleSize)) * moduleSize;
                    const y = Math.floor(Math.random() * (height / moduleSize)) * moduleSize;
                    const idx = (y * width + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    colors.add(`${r},${g},${b}`);
                }
                
                // Determine mode based on color count
                if (colors.size >= 7) return 'HIGH_DENSITY';
                if (colors.size >= 3) return 'BALANCED';
                return 'ROBUST';
            }

            findNearestColor(r, g, b, palette) {
                let minDist = Infinity;
                let nearestIndex = 0;
                
                palette.forEach((color, index) => {
                    const cr = parseInt(color.substr(1, 2), 16);
                    const cg = parseInt(color.substr(3, 2), 16);
                    const cb = parseInt(color.substr(5, 2), 16);
                    
                    const dist = Math.sqrt(
                        Math.pow(r - cr, 2) +
                        Math.pow(g - cg, 2) +
                        Math.pow(b - cb, 2)
                    );
                    
                    if (dist < minDist) {
                        minDist = dist;
                        nearestIndex = index;
                    }
                });
                
                return nearestIndex;
            }
        }

        // App state
        let stream = null;
        let isScanning = false;
        let isReceiving = false; // NEW: Only true after detecting start signal
        let scanInterval = null;
        let receivedFrames = new Map();
        let frameHashes = new Set(); // Track unique frames by hash
        let totalFrames = 0; // Total frames detected
        let expectedDataFrames = 0; // Expected number of data frames from metadata
        let totalDataBytes = []; // Changed from string to byte array
        let decoder = new SimpleVisualDecoder();
        let lastDetectionTime = 0;
        let detectionCooldown = 200; // ms between frame captures
        let startSignalDetected = false;
        let metadataReceived = false; // Track if we got the START frame
        let endFrameReceived = false; // Track if we got the END frame

        // Elements
        const videoElement = document.getElementById('videoElement');
        const canvasElement = document.getElementById('canvasElement');
        const startBtn = document.getElementById('startBtn');
        const startReceivingBtn = document.getElementById('startReceivingBtn');
        const stopBtn = document.getElementById('stopBtn');
        const saveBtn = document.getElementById('saveBtn');
        const scanIndicator = document.getElementById('scanIndicator');
        const ctx = canvasElement.getContext('2d');

        // Logging
        function addLog(message, type = 'info') {
            const logEntries = document.getElementById('logEntries');
            const entry = document.createElement('div');
            entry.className = `log-entry log-${type}`;
            
            const time = new Date().toLocaleTimeString();
            entry.innerHTML = `<span class="log-time">${time}</span><span>${message}</span>`;
            
            logEntries.insertBefore(entry, logEntries.firstChild);
            
            // Keep only last 20 logs
            while (logEntries.children.length > 20) {
                logEntries.removeChild(logEntries.lastChild);
            }
        }

        // Start camera
        startBtn.addEventListener('click', async () => {
            try {
                const enableAudio = document.getElementById('enableAudio').checked;
                
                const constraints = { 
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                };
                
                // Add audio if enabled
                if (enableAudio) {
                    constraints.audio = {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    };
                    addLog('Requesting camera + microphone access...', 'info');
                } else {
                    addLog('Requesting camera access...', 'info');
                }
                
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                
                videoElement.srcObject = stream;
                startBtn.disabled = true;
                startReceivingBtn.disabled = false; // Enable manual start
                stopBtn.disabled = false;
                isScanning = true;
                
                if (enableAudio) {
                    addLog('Camera + microphone started successfully', 'success');
                    setupAudioDetection(stream);
                    addLog('üéµ Waiting for audio start signal (triple beep)...', 'info');
                } else {
                    addLog('Camera started successfully', 'success');
                    addLog('üëÜ Click "Start Receiving" button when ready', 'info');
                }
                
                scanIndicator.textContent = 'Scanning...';
                scanIndicator.classList.add('active');
                
                // Start scanning
                scanInterval = setInterval(scanFrame, 100); // Scan every 100ms
                
            } catch (err) {
                addLog('Failed to access camera/microphone: ' + err.message, 'error');
                alert('Could not access camera/microphone. Please grant permissions and try again.');
            }
        });

        // Manual start receiving button
        startReceivingBtn.addEventListener('click', () => {
            if (!isReceiving && isScanning) {
                // Reset data collection
                receivedFrames.clear();
                frameHashes.clear();
                totalDataBytes = [];
                
                isReceiving = true;
                startSignalDetected = true;
                startReceivingBtn.disabled = true;
                addLog('üëç Manual start - Transfer beginning!', 'success');
                scanIndicator.textContent = 'Transfer Started - Capturing...';
                scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
            }
        });

        // Stop camera
        stopBtn.addEventListener('click', () => {
            // Reassemble and show data before stopping
            if (receivedFrames.size > 0) {
                handleTransferComplete();
            } else {
                stopScanning();
            }
        });

        function stopScanning() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            if (scanInterval) {
                clearInterval(scanInterval);
                scanInterval = null;
            }
            
            isScanning = false;
            isReceiving = false;
            startSignalDetected = false;
            startBtn.disabled = false;
            startReceivingBtn.disabled = true; // Reset manual button
            stopBtn.disabled = true;
            scanIndicator.textContent = 'Stopped';
            scanIndicator.classList.remove('active');
            scanIndicator.style.background = '';
            
            addLog('Scanning stopped', 'info');
        }

        // Audio detection setup
        function setupAudioDetection(mediaStream) {
            try {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(mediaStream);
                const analyser = audioContext.createAnalyser();
                
                analyser.fftSize = 2048;
                source.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                // Listen for audio beeps
                let lastBeepTime = 0;
                let beepSequence = [];
                
                function detectBeeps() {
                    if (!isScanning) return;
                    
                    analyser.getByteFrequencyData(dataArray);
                    
                    // Check for frequencies around 1000 Hz (base frequency)
                    // Bin index = frequency * fftSize / sampleRate
                    // For 1000 Hz at 44100 sample rate with 2048 FFT: ~46
                    const targetBin = Math.floor(1000 * analyser.fftSize / audioContext.sampleRate);
                    const binRange = 10; // Check ¬±10 bins
                    
                    let maxAmplitude = 0;
                    let peakFrequency = 0;
                    for (let i = Math.max(0, targetBin - binRange); i < Math.min(bufferLength, targetBin + binRange); i++) {
                        if (dataArray[i] > maxAmplitude) {
                            maxAmplitude = dataArray[i];
                            peakFrequency = (i * audioContext.sampleRate) / analyser.fftSize;
                        }
                    }
                    
                    // Detect beep (threshold: 150/255)
                    if (maxAmplitude > 150) {
                        const now = Date.now();
                        if (now - lastBeepTime > 50) { // Debounce 50ms
                            beepSequence.push({ freq: peakFrequency, time: now });
                            
                            // Keep only recent beeps (last 2 seconds)
                            beepSequence = beepSequence.filter(b => now - b.time < 2000);
                            
                            // Detect triple beep pattern (metadata announcement)
                            if (beepSequence.length >= 3 && !startSignalDetected) {
                                const lastThree = beepSequence.slice(-3);
                                const timeDiff1 = lastThree[1].time - lastThree[0].time;
                                const timeDiff2 = lastThree[2].time - lastThree[1].time;
                                
                                // Check if beeps are evenly spaced (~150ms apart)
                                if (timeDiff1 > 100 && timeDiff1 < 200 && timeDiff2 > 100 && timeDiff2 < 200) {
                                    // Reset data collection
                                    receivedFrames.clear();
                                    frameHashes.clear();
                                    totalDataBytes = [];
                                    
                                    startSignalDetected = true;
                                    isReceiving = true;
                                    startReceivingBtn.disabled = true; // Disable manual button
                                    addLog('üéµ START SIGNAL DETECTED - Transfer beginning!', 'success');
                                    scanIndicator.textContent = 'Transfer Started - Capturing...';
                                    scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
                                }
                            }
                            
                            // Log regular sync beeps
                            if (startSignalDetected) {
                                addLog(`üîä Sync beep (${Math.round(peakFrequency)} Hz)`, 'info');
                            }
                            
                            lastBeepTime = now;
                        }
                    }
                    
                    requestAnimationFrame(detectBeeps);
                }
                
                detectBeeps();
                addLog('Audio detection active - listening for sync beeps', 'success');
                
            } catch (err) {
                addLog('Audio detection setup failed: ' + err.message, 'error');
            }
        }

        // Check for special control frames (metadata/end markers)
        function checkForControlFrame(imageData) {
            // Look for red marker in bottom-right corner (12x12 pixels)
            const width = imageData.width;
            const height = imageData.height;
            const data = imageData.data;
            
            let redPixelCount = 0;
            const checkSize = 12;
            
            // Check bottom-right corner for red marker
            for (let y = height - checkSize; y < height; y++) {
                for (let x = width - checkSize; x < width; x++) {
                    const idx = (y * width + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    
                    // Check if predominantly red (R > 200, G < 100, B < 100)
                    if (r > 200 && g < 100 && b < 100) {
                        redPixelCount++;
                    }
                }
            }
            
            // If enough red pixels found, it's a control frame
            if (redPixelCount > 50) {
                return { isControlFrame: true };
            }
            
            return { isControlFrame: false };
        }

        // Extract frame count from metadata frame
        function extractFrameCountFromMetadata(imageData) {
            try {
                // Decode the frame data using the visual decoder
                const decoder = new SimpleVisualDecoder('BALANCED');
                const decodedBytes = decoder.decodeFrame(imageData);
                
                if (!decodedBytes || decodedBytes.length < 8) {
                    return 0;
                }
                
                // Check for "META" magic header
                if (decodedBytes[0] === 77 && decodedBytes[1] === 69 && 
                    decodedBytes[2] === 84 && decodedBytes[3] === 65) {
                    
                    // Extract frame count (bytes 4-7, big-endian)
                    const frameCount = (decodedBytes[4] << 24) | 
                                     (decodedBytes[5] << 16) | 
                                     (decodedBytes[6] << 8) | 
                                     decodedBytes[7];
                    
                    // Extract filename if present
                    if (decodedBytes.length > 10) {
                        const filenameLength = (decodedBytes[8] << 8) | decodedBytes[9];
                        if (decodedBytes.length >= 10 + filenameLength) {
                            const filenameBytes = decodedBytes.slice(10, 10 + filenameLength);
                            const filename = new TextDecoder().decode(filenameBytes);
                            console.log('üìÑ Original filename:', filename);
                            // Store filename for later use
                            window.originalFilename = filename;
                        }
                    }
                    
                    console.log('üìä Metadata detected - Expected frames:', frameCount);
                    return frameCount;
                }
                
                // Check for "END!" magic header
                if (decodedBytes[0] === 69 && decodedBytes[1] === 78 && 
                    decodedBytes[2] === 68 && decodedBytes[3] === 33) {
                    
                    const frameCount = (decodedBytes[4] << 24) | 
                                     (decodedBytes[5] << 16) | 
                                     (decodedBytes[6] << 8) | 
                                     decodedBytes[7];
                    
                    console.log('üèÅ End frame detected - Total frames:', frameCount);
                    return -1; // Special marker for end frame
                }
                
            } catch (error) {
                console.error('Error extracting metadata:', error);
            }
            
            return 0;
        }

        // Scan frame for QR code
        function scanFrame() {
            if (!isScanning) return;

            // Cooldown between detections
            const now = Date.now();
            if (now - lastDetectionTime < detectionCooldown) return;

            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            
            if (canvasElement.width === 0) return;

            ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            const imageData = ctx.getImageData(0, 0, canvasElement.width, canvasElement.height);
            
            // Check for control frames (START/END markers)
            const controlCheck = checkForControlFrame(imageData);
            
            if (controlCheck.isControlFrame) {
                // This is a metadata or end frame - try to extract info
                const frameCount = extractFrameCountFromMetadata(imageData);
                
                if (frameCount > 0 && !metadataReceived) {
                    // This is the START metadata frame
                    metadataReceived = true;
                    expectedDataFrames = frameCount;
                    addLog(`üìã START frame detected - Expecting ${frameCount} data frames`, 'success');
                    
                    scanIndicator.textContent = 'Receiving data...';
                    scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
                    
                    // Auto-start receiving on metadata frame
                    if (!isReceiving) {
                        isReceiving = true;
                        startSignalDetected = true;
                        startReceivingBtn.disabled = true;
                    }
                    return;
                } else if (frameCount === -1) {
                    // This is the END frame
                    if (!endFrameReceived) {
                        endFrameReceived = true;
                        addLog('üèÅ END frame detected - Checking completion...', 'info');
                        
                        // Check if we have all data frames
                        checkTransferCompletion();
                    }
                    return;
                } else if (!metadataReceived) {
                    // Control frame but couldn't decode - treat as START anyway
                    metadataReceived = true;
                    addLog('üìã START frame detected - Transfer beginning!', 'success');
                    
                    scanIndicator.textContent = 'Receiving data...';
                    scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
                    
                    if (!isReceiving) {
                        isReceiving = true;
                        startSignalDetected = true;
                        startReceivingBtn.disabled = true;
                    }
                    return;
                }
            }
            
            // Use our custom decoder for data frames
            const decoded = decoder.decodeFrame(imageData);
            
            if (decoded && decoded.detected) {
                // Only capture frames after start signal (manual button or audio beep)
                if (!isReceiving) {
                    const enableAudio = document.getElementById('enableAudio').checked;
                    if (enableAudio) {
                        scanIndicator.textContent = 'Waiting for audio start signal...';
                    } else {
                        scanIndicator.textContent = 'Click "Start Receiving" to begin...';
                    }
                    return;
                }
                
                lastDetectionTime = now;
                
                // Check if this is a new frame (by hash)
                if (!frameHashes.has(decoded.hash)) {
                    frameHashes.add(decoded.hash);
                    
                    // Extract frame ID from the decoded data if available
                    // For now, use received order but store the data separately
                    const frameId = receivedFrames.size;
                    receivedFrames.set(frameId, {
                        data: decoded.data,
                        hash: decoded.hash,
                        timestamp: Date.now()
                    });
                    
                    addLog(`‚úì Frame ${frameId + 1} captured (${decoded.data.length} bytes)`, 'success');
                    scanIndicator.textContent = `Captured ${frameId + 1} frames`;
                    
                    updateStats();
                    
                    // Auto-check completion if we received END frame
                    if (endFrameReceived) {
                        checkTransferCompletion();
                    }
                }
            }
        }

        // Reassemble data frames in correct order
        function reassembleData() {
            totalDataBytes = [];
            
            // Sort frames by their order and concatenate
            const sortedFrames = Array.from(receivedFrames.entries())
                .sort((a, b) => a[0] - b[0]); // Sort by frame number
            
            for (const [frameId, frameData] of sortedFrames) {
                totalDataBytes.push(...frameData.data);
            }
            
            console.log(`üì¶ Reassembled ${sortedFrames.length} frames into ${totalDataBytes.length} bytes`);
            console.log(`üîç First 16 bytes:`, totalDataBytes.slice(0, 16));
        }

        // Check if transfer is complete and auto-stop
        function checkTransferCompletion() {
            const receivedCount = receivedFrames.size;
            const expectedCount = expectedDataFrames;
            
            if (expectedCount > 0 && receivedCount >= expectedCount) {
                // We have all expected frames!
                addLog(`‚úÖ Transfer COMPLETE! Received all ${receivedCount}/${expectedCount} frames`, 'success');
                scanIndicator.textContent = `Complete! ${receivedCount} frames`;
                scanIndicator.style.background = 'rgba(76, 175, 80, 0.9)';
                
                // Auto-stop receiving (reassembly happens in handleTransferComplete)
                setTimeout(() => {
                    handleTransferComplete();
                }, 1000); // Small delay to show completion message
            } else if (endFrameReceived) {
                // We saw END frame but missing some data frames
                const missing = expectedCount - receivedCount;
                addLog(`‚ö†Ô∏è END detected but missing ${missing} frames. Keep scanning...`, 'warn');
                scanIndicator.textContent = `${receivedCount}/${expectedCount} frames (${missing} missing)`;
            }
        }

        // Update statistics
        function updateStats() {
            const detected = receivedFrames.size;
            const total = expectedDataFrames || detected; // Use expected count if known
            const progress = total > 0 ? (detected / total) * 100 : 0;
            const successRate = total > 0 ? ((detected / total) * 100).toFixed(1) : 0;

            // Calculate total data size from all received frames
            let totalBytes = 0;
            receivedFrames.forEach(frameData => {
                totalBytes += frameData.data.length;
            });

            document.getElementById('framesDetected').textContent = detected;
            document.getElementById('successRate').textContent = successRate + '%';
            document.getElementById('progress').textContent = progress.toFixed(1) + '%';
            document.getElementById('progressBar').style.width = Math.min(progress, 100) + '%';
            document.getElementById('dataReceived').textContent = (totalBytes / 1024).toFixed(1) + ' KB';
            
            // Enable save button if we have any data
            if (totalBytes > 0) {
                saveBtn.disabled = false;
                document.getElementById('receivedData').classList.add('active');
                
                // Show simple frame count preview (don't reassemble until complete)
                const preview = `Receiving data...\n${detected} frames captured\n${(totalBytes / 1024).toFixed(2)} KB received`;
                document.getElementById('dataPreview').textContent = preview;
            }
        }

        // Transfer complete
        function handleTransferComplete() {
            stopScanning();
            
            // CRITICAL: Reassemble data in correct order first
            reassembleData();
            
            document.getElementById('receivedData').classList.add('active');
            
            // Detect file type from reassembled data
            const fileType = detectFileType(totalDataBytes);
            
            // Show preview based on file type
            const previewBytes = totalDataBytes.slice(0, 500);
            let preview = '';
            
            // Add file type header
            preview = `üìÅ File Type: ${fileType.description} (.${fileType.extension})\n`;
            preview += `üìä Size: ${totalDataBytes.length.toLocaleString()} bytes (${(totalDataBytes.length / 1024).toFixed(2)} KB)\n\n`;
            
            if (fileType.extension === 'txt' || fileType.extension === 'html' || fileType.extension === 'xml') {
                // Text files - show content
                try {
                    const decoder = new TextDecoder('utf-8', { fatal: true });
                    preview += 'Content Preview:\n' + decoder.decode(new Uint8Array(previewBytes));
                } catch (e) {
                    preview += 'Binary data (hex): ' + previewBytes.map(b => b.toString(16).padStart(2, '0')).join(' ');
                }
            } else {
                // Binary files - show hex dump
                preview += 'Binary Data (hex preview):\n';
                preview += previewBytes.map(b => b.toString(16).padStart(2, '0')).join(' ');
            }
            
            document.getElementById('dataPreview').textContent = preview + 
                (totalDataBytes.length > 500 ? '\n... (truncated)' : '');
            
            saveBtn.disabled = false;
            addLog(`Transfer complete! Detected: ${fileType.description} üéâ`, 'success');
            scanIndicator.textContent = 'Complete!';
        }

        // Detect file type from magic numbers (file signatures)
        function detectFileType(bytes) {
            if (!bytes || bytes.length < 4) {
                return { extension: 'bin', mimeType: 'application/octet-stream', description: 'Unknown' };
            }

            // Convert first bytes to hex for comparison
            const header = Array.from(bytes.slice(0, 16))
                .map(b => b.toString(16).padStart(2, '0'))
                .join('');

            // Debug: log the first bytes
            console.log('üîç File header (first 16 bytes):', header);
            console.log('üîç First 4 bytes as array:', Array.from(bytes.slice(0, 4)));

            // Common file signatures
            const signatures = [
                // Images
                { magic: 'ffd8ff', extension: 'jpg', mimeType: 'image/jpeg', description: 'JPEG Image' },
                { magic: '89504e47', extension: 'png', mimeType: 'image/png', description: 'PNG Image' },
                { magic: '47494638', extension: 'gif', mimeType: 'image/gif', description: 'GIF Image' },
                { magic: '424d', extension: 'bmp', mimeType: 'image/bmp', description: 'Bitmap Image' },
                { magic: '49492a00', extension: 'tif', mimeType: 'image/tiff', description: 'TIFF Image' },
                { magic: '4d4d002a', extension: 'tif', mimeType: 'image/tiff', description: 'TIFF Image' },
                { magic: '52494646', extension: 'webp', mimeType: 'image/webp', description: 'WebP Image' },
                
                // Documents
                { magic: '25504446', extension: 'pdf', mimeType: 'application/pdf', description: 'PDF Document' },
                { magic: '504b0304', extension: 'zip', mimeType: 'application/zip', description: 'ZIP Archive' },
                { magic: 'd0cf11e0a1b11ae1', extension: 'doc', mimeType: 'application/msword', description: 'MS Word Document' },
                
                // Office (modern - all ZIP-based)
                { magic: '504b030414000600', extension: 'docx', mimeType: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', description: 'Word Document' },
                { magic: '504b030414000800', extension: 'xlsx', mimeType: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', description: 'Excel Spreadsheet' },
                
                // Text/Code
                { magic: 'efbbbf', extension: 'txt', mimeType: 'text/plain', description: 'Text File (UTF-8 BOM)' },
                { magic: '3c3f786d6c', extension: 'xml', mimeType: 'text/xml', description: 'XML Document' },
                { magic: '3c68746d6c', extension: 'html', mimeType: 'text/html', description: 'HTML Document' },
                { magic: '3c21444f43545950', extension: 'html', mimeType: 'text/html', description: 'HTML Document' },
                
                // Media
                { magic: '1a45dfa3', extension: 'mkv', mimeType: 'video/x-matroska', description: 'Matroska Video' },
                { magic: '000001ba', extension: 'mpg', mimeType: 'video/mpeg', description: 'MPEG Video' },
                { magic: '000001b3', extension: 'mpg', mimeType: 'video/mpeg', description: 'MPEG Video' },
                { magic: '66747970', extension: 'mp4', mimeType: 'video/mp4', description: 'MP4 Video' },
                { magic: '494433', extension: 'mp3', mimeType: 'audio/mpeg', description: 'MP3 Audio' },
                { magic: 'fff1', extension: 'aac', mimeType: 'audio/aac', description: 'AAC Audio' },
                { magic: 'fff9', extension: 'aac', mimeType: 'audio/aac', description: 'AAC Audio' },
                { magic: '4f676753', extension: 'ogg', mimeType: 'audio/ogg', description: 'OGG Audio' },
                
                // Archives
                { magic: '1f8b', extension: 'gz', mimeType: 'application/gzip', description: 'GZIP Archive' },
                { magic: '377abcaf271c', extension: '7z', mimeType: 'application/x-7z-compressed', description: '7-Zip Archive' },
                { magic: '526172211a07', extension: 'rar', mimeType: 'application/x-rar-compressed', description: 'RAR Archive' },
                
                // Executables
                { magic: '4d5a', extension: 'exe', mimeType: 'application/x-msdownload', description: 'Windows Executable' },
                { magic: '7f454c46', extension: 'elf', mimeType: 'application/x-executable', description: 'Linux Executable' },
            ];

            // Check against known signatures
            for (const sig of signatures) {
                if (header.startsWith(sig.magic)) {
                    console.log('‚úÖ Matched signature:', sig.description);
                    return sig;
                }
            }

            console.log('‚ùå No signature match found');

            // Check if it's likely text (all printable ASCII + common whitespace)
            let likelyText = true;
            const sampleSize = Math.min(512, bytes.length);
            for (let i = 0; i < sampleSize; i++) {
                const byte = bytes[i];
                // Allow printable ASCII (32-126), newlines (10,13), tabs (9)
                if (!(byte >= 32 && byte <= 126) && byte !== 10 && byte !== 13 && byte !== 9) {
                    likelyText = false;
                    break;
                }
            }

            if (likelyText) {
                console.log('üìù Detected as text file');
                return { extension: 'txt', mimeType: 'text/plain', description: 'Text File' };
            }

            // Unknown binary file
            console.log('üì¶ Unknown binary file');
            return { extension: 'bin', mimeType: 'application/octet-stream', description: 'Binary File' };
        }

        // Save file
        saveBtn.addEventListener('click', () => {
            // Convert byte array to Uint8Array and create binary blob
            const uint8Array = new Uint8Array(totalDataBytes);
            
            // Detect file type
            const fileType = detectFileType(uint8Array);
            console.log('üìù Detected file type:', fileType.description, `(.${fileType.extension})`);
            
            const blob = new Blob([uint8Array], { type: fileType.mimeType });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            
            // Use original filename if available, otherwise use detected extension
            if (window.originalFilename) {
                a.download = window.originalFilename;
            } else {
                // Generate filename with detected extension
                const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5);
                a.download = `received_${timestamp}.${fileType.extension}`;
            }
            
            addLog(`üíæ Saving as: ${a.download} (${fileType.description})`, 'success');
            a.click();
            URL.revokeObjectURL(url);
            
            addLog(`File saved successfully (${totalDataBytes.length} bytes)`, 'success');
        });

        // Initialize
        addLog('Receiver ready. Click "Start Camera" to begin.', 'info');
    </script>
</body>
</html>
